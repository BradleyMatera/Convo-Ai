# Convo-AI Isolated

A local, isolated conversational AI system with voice and text input capabilities.

[![Python Version](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸŒŸ Features

- ğŸ¤ Voice input with real-time transcription
- ğŸ“ Text input support
- ğŸ¤– Local LLM integration with Ollama
- ğŸ”Š Text-to-speech with XTTS v2
- ğŸŒ Web interface for easy interaction
- ğŸ“Š Conversation history and logging
- ğŸ”’ Privacy-focused (all processing done locally)

## ğŸš€ Quick Start

See the [HOWTO.md](HOWTO.md) for detailed installation and usage instructions.

```bash
# Clone the repository
git clone https://github.com/yourusername/convo-ai-isolated.git
cd convo-ai-isolated

# Install dependencies
pip install -r requirements.txt

# Start the server
python server.py

# In a new terminal, start the client
python talk.py
```

## ğŸ› ï¸ Tech Stack

- **Backend**: Python, FastAPI
- **Speech-to-Text**: OpenAI's Whisper
- **LLM**: Ollama (local)
- **Text-to-Speech**: XTTS v2
- **Frontend**: HTML, JavaScript
- **Communication**: WebSocket

## ğŸ“ Project Structure

```
convo-ai-isolated/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.py
â”‚   â””â”€â”€ talk.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/
â”œâ”€â”€ logs/
â”œâ”€â”€ tts_cache/
â”œâ”€â”€ config.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ HOWTO.md
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) for the local LLM
- [OpenAI Whisper](https://github.com/openai/whisper) for speech recognition
- [XTTS](https://github.com/coqui-ai/TTS) for text-to-speech
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework 